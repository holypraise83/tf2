{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/minsuk-heo/tf2/blob/master/jupyter_notebooks/08.RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, SimpleRNN, TimeDistributed\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Cell Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape\n",
    "inputs = Input(shape=(1,2))\n",
    "# output shape, return state, use tanh as activation function\n",
    "output, state = SimpleRNN(3, return_state=True, activation='tanh')(inputs)\n",
    "model = Model(inputs=inputs, outputs=[output, state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  [[-0.993022   -0.8782703   0.13555866]]\n",
      "state:  [[-0.993022   -0.8782703   0.13555866]]\n"
     ]
    }
   ],
   "source": [
    "# test input\n",
    "data = np.array([[ [1,2] ]])\n",
    "# print output, state\n",
    "output, state = model.predict(data)\n",
    "print(\"output: \",output)\n",
    "print(\"state: \",state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple_rnn/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[-0.9880387 , -0.12899536,  0.68050313],\n",
       "       [-0.91964287, -0.61957824, -0.2720524 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for input\n",
    "model.layers[1].weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple_rnn/recurrent_kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[-0.47471285, -0.4501174 ,  0.7563346 ],\n",
       "       [ 0.57666993,  0.49011993,  0.6536315 ],\n",
       "       [ 0.66490567, -0.7464427 , -0.02690291]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for state\n",
    "model.layers[1].weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple_rnn/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias\n",
    "model.layers[1].weights[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sequence tagging example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "John = [1,0,0]\n",
    "loves = [0,1,0]\n",
    "Jane = [0,0,1]\n",
    "\n",
    "X = np.array([\n",
    "    [ John, loves, Jane ],\n",
    "    [ Jane, loves, John ]\n",
    "]).astype(np.float32)\n",
    "\n",
    "S = [0] # subject\n",
    "V = [1] # verb\n",
    "O = [2] # object\n",
    "y = np.array([[S, V, O], [S, V, O]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape\n",
    "inputs = Input(shape=(3, 3))\n",
    "# output shape, return state, return sequence\n",
    "output, state = SimpleRNN(3, return_state=True, return_sequences=True)(inputs)\n",
    "model = Model(inputs=inputs, outputs=[output, state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print output, state\n",
    "output, state = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John loves Jane:  [[ 0.7114806   0.00293278 -0.4700191 ]\n",
      " [-0.07926637 -0.4950598   0.25483623]\n",
      " [-0.30115584  0.65368456  0.63261586]]\n",
      "Jane loves John:  [[-0.34041515  0.23454879  0.7097573 ]\n",
      " [ 0.8615997  -0.00218594  0.6958208 ]\n",
      " [ 0.2863685   0.43382952  0.29268172]]\n"
     ]
    }
   ],
   "source": [
    "print(\"John loves Jane: \",output[0])\n",
    "print(\"Jane loves John: \",output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John loves Jane: state:  [-0.30115584  0.65368456  0.63261586]\n",
      "Jane loves John: state:  [0.2863685  0.43382952 0.29268172]\n"
     ]
    }
   ],
   "source": [
    "# the state value is same with the last output\n",
    "print(\"John loves Jane: state: \",state[0])\n",
    "print(\"Jane loves John: state: \",state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 3, 3)              21        \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 3, 3)              12        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x640b40950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(3, 3), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(3, activation=\"softmax\")))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())\n",
    "# train, takes 30sec, if you want to monitor progreses, change verbose=1\n",
    "model.fit(X, y, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(X, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [0, 1, 2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "\n",
    "# 0 : Subject\n",
    "# 1 : Verb\n",
    "# 2 : Object\n",
    "np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Classification\n",
    "classify movie review into positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = [\n",
    "         {'review': 'this is the best movie', 'sentiment': 'positive'},\n",
    "         {'review': 'i recommend you watch this movie', 'sentiment': 'positive'},\n",
    "         {'review': 'it was waste of money and time', 'sentiment': 'negative'},\n",
    "         {'review': 'the worst movie ever', 'sentiment': 'negative'}\n",
    "    ]\n",
    "df = pd.DataFrame(movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the best movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i recommend you watch this movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it was waste of money and time</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the worst movie ever</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review sentiment\n",
       "0            this is the best movie  positive\n",
       "1  i recommend you watch this movie  positive\n",
       "2    it was waste of money and time  negative\n",
       "3              the worst movie ever  negative"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab2int(df):\n",
    "    d = {}\n",
    "    vocab = set()\n",
    "    df['review'].str.split().apply(vocab.update)\n",
    "    for idx, word in enumerate(vocab):\n",
    "        d[word] = idx\n",
    "    return d\n",
    "\n",
    "vocab2_int = get_vocab2int(df)\n",
    "vocab_size = len(vocab2_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode words into integer\n",
    "reviews = df['review'].tolist()\n",
    "encoded_reviews = []\n",
    "for review in reviews:\n",
    "    tokens = review.split(\" \")\n",
    "    review_encoding = []\n",
    "    for token in tokens:\n",
    "        review_encoding.append(vocab2_int[token])\n",
    "    encoded_reviews.append(review_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 9, 11, 12, 15]\n",
      "[0, 10, 16, 6, 13, 15]\n",
      "[7, 3, 17, 5, 14, 8, 2]\n",
      "[11, 4, 15, 1]\n"
     ]
    }
   ],
   "source": [
    "# encoded reviews\n",
    "print(encoded_reviews[0])\n",
    "print(encoded_reviews[1])\n",
    "print(encoded_reviews[2])\n",
    "print(encoded_reviews[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(df):\n",
    "    max_length = 0\n",
    "    for row in df['review']:\n",
    "        if len(row.split(\" \")) > max_length:\n",
    "            max_length = len(row.split(\" \"))\n",
    "    return max_length\n",
    "\n",
    "# max_length is used for max sequence of input\n",
    "max_length = get_max_length(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if review is short, fill in zero padding and make all sentence length to be same as max_length\n",
    "padded_reviews_encoding = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = df['sentiment'].tolist()\n",
    "def sentiment_encode(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]\n",
    "\n",
    "# encoded sentiment\n",
    "encoded_sentiment = [sentiment_encode(sentiment) for sentiment in sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 3, input_length=max_length))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(padded_reviews_encoding)\n",
    "train_Y = np.array(encoded_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 4 samples\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 2s 462ms/sample - loss: 0.6903 - accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.6840 - accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.6778 - accuracy: 0.7500\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.6714 - accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 7ms/sample - loss: 0.6647 - accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 6ms/sample - loss: 0.6576 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.6501 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.6421 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.6336 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.6245 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.6147 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.6041 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.5928 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.5805 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.5674 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.5533 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.5381 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.5219 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.5045 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.4860 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.4663 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.4455 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.4235 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.4004 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.3764 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.3515 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.3259 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2998 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.2735 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.2472 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 8ms/sample - loss: 0.2213 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1961 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1720 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1493 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.1283 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.1092 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0920 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0770 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0640 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0529 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 3ms/sample - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 5ms/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 4ms/sample - loss: 0.0087 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x641ee4d90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(train_X, train_Y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/1 - 0s - loss: 0.0076 - accuracy: 1.0000\n",
      "Test score: 0.007553538773208857\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(train_X, train_Y, verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
